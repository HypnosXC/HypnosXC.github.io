---
permalink: /
title: "About me ([CV](https://hypnosxc.github.io/files/CV_ChenXu.pdf))"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a recent graduate in [MCG GROUP](https://mcg.nju.edu.cn/) at [Nanjing University](https://cs.nju.edu.cn/main.htm/), supervised by [Prof. Limin Wang](https://wanglimin.github.io/). I just obtained my Master degree in 2024, and I also obtained the B.Sc degree from [Nanjing University](https://cs.nju.edu.cn/main.htm/) in 2021, where I was fortunate to cross paths with my mentor, setting the course for my academic journey.

My academic pursuits are centered on the exciting fields of computer vision and graphics. Currently, I am particularly working in the development of Generative Models and **Accelerating Diffuison Models**. I have a consistent focus on foundation Multi-modal models, with a preference for Vision-Language Models, and I am keen on advancing **Efficient and Transfer Learning methodologies** based on these models.

<font size=2 color=red>**NEW**: I am actively seeking Ph.D. opportunities in the upcoming 2025. If you see potential alignment with my research interests and your program, please feel free to reach out to me directly via email. I am eager to explore collaborative possibilities and continue my contributions to the field.</font>
<br><br>

Research
-----

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one"><div class="two" id='dmn_image'>
          <img src='images/SPLAM.jpg' width="160">
          </div></div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <strong>Accelerating Image Generation with Sub-Path Linear Approximation Model
        </strong>
        <br>
        <strong>Chen Xu*</strong>, Tianhui Song*, Weixin Feng, Xubin Li, Tiezheng Ge, Bo Zheng, <a href="https://wanglimin.github.io/">Limin Wang</a>
        <br>
        <em>ECCV <strong>Oral</strong></em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2404.13903">arXiv</a > /
        <a href="https://github.com/MCG-NJU/SPLAM">code</a > /
        <a href="https://subpath-linear-approx-model.github.io/">project</a >
        <p>Sub-path Linear Approximation Models (SPLAM) give a continous and progressive error estimation for separated PF-ODE sub-paths and generate images with high quality and smaller cumulative errors.
        </p>
      </td>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one"><div class="two" id='dmn_image'>
          <img src='images/TTPT.jpg' width="160"></div></div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <strong>Efficient Test-Time Prompt Tuning for Vision-Language Models
        </strong>
        <br>
        Yuhan Zhu, Guozhen Zhang, <strong>Chen Xu</strong>, Haocheng Shen, Xiaoxin Chen, <a href="https://mcg.nju.edu.cn/member/gswu/en/index.html">Gangshan Wu</a>, <a href="https://wanglimin.github.io/">Limin Wang</a>
        <br>
        <em>Arxiv </em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2408.05775">arXiv</a >
      </td>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one"><div class="two" id='dmn_image'>
                  <img src='images/ProVP.jpg' width="160"></div></div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <strong>Progressive Visual Prompt Learning with Contrastive Feature Re-formation
        </strong>
        <br>
        <strong>Chen Xu*</strong>, Yuhan Zhu*, Haocheng Shen, Boheng Chen, Yixuan Liao, Xiaoxin Chen, <a href="https://mcg.nju.edu.cn/member/gswu/en/index.html">Gangshan Wu</a>, <a href="https://wanglimin.github.io/">Limin Wang</a>
        <br>
        <em>IJCV</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2304.08386">arXiv</a > /
        <a href="https://github.com/MCG-NJU/ProVP">code</a > 
        <p>We present Progressive Visual Prompt Learning with Contrastive Feature Re-formation (ProVP-Ref), a novel visual prompt learning architecture based on Vision-language Models.
        </p>
      </td>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one"><div class="two" id='dmn_image'>
          <img src='images/DPL.jpg' width="160"></div></div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <strong>DPL: Decoupled Prompt Learning for Vision-Language Models
        </strong>
        <br>
        <strong>Chen Xu*</strong>, Yuhan Zhu*, Haocheng Shen, Boheng Chen, Yixuan Liao, Xiaoxin Chen, <a href="https://mcg.nju.edu.cn/member/gswu/en/index.html">Gangshan Wu</a>, <a href="https://wanglimin.github.io/">Limin Wang</a>
        <br>
        <em>Arxiv</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2308.10061">arXiv</a >
        <p>We present Decoupled Prompt Learning (DPL), a general prompt learning architecture which decouples the attention calculations between the input instance and learnable prompts, and then recombines them to establish a more effective and effcient learning for Vision-language Models with better generalization ablity.
        </p>
      </td>
